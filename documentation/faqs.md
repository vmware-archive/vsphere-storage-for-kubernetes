---
title: FAQs
---

## What is the biggest Kubernetes cluster it has been tested for?
It has been tested on 500 node Kubernetes cluster so far. Please refer to this [section](/vsphere-storage-for-kubernetes/documentation/largescaledeployment.html) for details about recommended configuration.


## Where can I find required Roles and Privileges for the vCenter User for vSphere Cloud Provider?
 Please refer to this [section](/vsphere-storage-for-kubernetes/documentation/existing.html#create-roles-add-privileges-to-roles-and-assign-them-to-the-vsphere-cloud-provider-user-and-vsphere-entities).


## Which vSphere Datastore types are supported by vSphere Cloud Provider?
VMFS, NFS, vSAN and VVOl datastore types are supported by vSphere Cloud Provider.

## Can SPBM be used with dynamic volume provisioning?
Please refer to this [section](/vsphere-storage-for-kubernetes/documentation/policy-based-mgmt.html). 
Also refer to [Storage Policy Management inside kubernetes](https://github.com/kubernetes/examples/blob/master/staging/volumes/vsphere/README.md#storage-policy-management-inside-kubernetes) for more details.


## How is running containers on vSphere Integrated Containers different from running them on Kubernetes on vSphere?
VIC is infrastructure platform to run containerized workloads alongside traditional applications whereas vSphere Cloud provider provides an interface to run and take advantage of vSphere storage for workloads running on Kubernetes

## Can I run it on a single node cluster on my laptop?
Yes as long as laptop supports nested virtualization you can try it on your laptop.

## Which Kubernetes distribution is supported?
vSphere Cloud Provider is available in vanilla Kubernetes and all distributions using Kubernetes v1.5 and above should support it. Please refer this [section.](/vsphere-storage-for-kubernetes/documentation/prereq.html)

## Can we deploy multiple Kubernetes Cluster on one vCenter?
Yes. Using resource pool and maintaining the VMs from each Kubernetes cluster in their respective VM folder you can run multiple Kubernetes cluster on vCenter.


## Can Kubernetes Cluster access storage from another vCenter?
Yes. vSphere supports shared storage across multiple vCenters. User can use shared storage in multiple Kubernetes Clusters.

## Which Operating System are supported?
We support Photon, Ubuntu, Core OS, please check this section for [details](/vsphere-storage-for-kubernetes/documentation/prereq.html)


## How Kubernetes volumes can be made resilient to failures on vSAN datastore?
Please check the HA section for [details.](/vsphere-storage-for-kubernetes/documentation/ha.html)

## Can I enable SDRS on VMs hosting kubernetes cluster?
No.

## Can we have a setting to ensure all dynamic PVs with have default policy Retain (instead of delete)? Or can we request the desired policy from the moment we request the PV via the PVC?
If the volume was dynamically provisioned, then the default reclaim policy is set to “delete”.  This means that, by default, when the PVC is deleted, the underlying PV and storage asset will also be deleted.
If you want to retain the data stored on the volume, then you must change the reclaim policy from “delete” to “retain” after the PV is provisioned. You cannot directly set to retain PV from PVC request for dynamic volumes. [Details](https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/)

## How do we resize the existing dynamic volumes? If we update the PVC with the new desired size, is it enough?
Support for resizing existing dynamic volume is not yet there.
Proposal is out for [review.](https://github.com/gnufied/community/blob/91b41028182a5291b4eccbf88f8065f66b2b7eed/contributors/design-proposals/grow-volume-size.md)

## Can we create ReadWriteMany volumes with VSphere storage, with pods on different machines?
ReadWriteMany is not supported with Pods on different machine. This is supported on the collocated pods on the same node.

## Is it mandatory to have all the machines in the same datastore? If so, it's a very strong limitation for us.
It is not mandatory to keep all node VMs on the same datastore.  But make sure node VM has access to volumes datastores.


## Can we have the disk uuid enabled by default, so we don't need to do it machine by machine? What would be the risks of having it by default.
You can enable disk UUID by default, while creating VM. Just add this parameter at
Customize hardware -> VM Options -> Configuration Parameters -> Edit Configuration

## Is it mandatory to have all the machines in the same directory?
Current code base requires Master and Node VMs to be present under one VM folder. Each Kubernetes Cluster deployed in vSphere, should be placed in their respective VM folder, else under root folder.


## Can Kubernetes Cluster span across multiple vCenters?
With Kubernetes version 1.9.x vSphere cloud provider supports Kubernetes cluster spanning across multiple ESXi clusters, vSphere Datacenters and vCenters. All Kubernetes node VMs must have access to shared storage.
